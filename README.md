ğŸ“Š MLflow Fundamentals, Tracking & Hyperparameter Tuning

This repository is a hands-on exploration of MLflow covering everything from basics to real-world experiment tracking.
It demonstrates local and server-based tracking (via DAGsHub), MLflow autologging, hyperparameter tuning, and a clear comparison between MLflow and DVC.

This project is focused on understanding ML experiment management, not just training a model.

ğŸ¯ What This Repository Covers

âœ” MLflow fundamentals (core concepts)
âœ” MLflow autologging
âœ” Local experiment tracking
âœ” Server-based experiment tracking using DAGsHub
âœ” Hyperparameter tuning with MLflow runs
âœ” Logging parameters, metrics, and artifacts
âœ” Confusion matrix logging
âœ” MLflow vs DVC â€” roles, differences, and when to use what



ğŸ§  Key Concepts Demonstrated
ğŸ”¹ MLflow Basics

Experiments & runs

Parameters, metrics, and artifacts

Tracking URI

Backend store vs artifact store

ğŸ”¹ MLflow Autologging

Automatic logging of:

Parameters

Metrics

Models

Reduced boilerplate

Comparison with manual logging

ğŸ”¹ Server-Based Tracking (DAGsHub)

Remote MLflow tracking server

Centralized experiment management

Team-friendly experiment visibility

Persistent experiment history

ğŸ”¹ Hyperparameter Tuning

Multiple experiment runs

Parameter comparison across runs

Metric-based evaluation

Selecting the best-performing configuration

ğŸ”¹ MLflow vs DVC (Conceptual Comparison)
Aspect	MLflow	DVC
Purpose	Experiment tracking	Data & pipeline versioning
Focus	Parameters, metrics, models	Datasets, pipelines
Tracking	Runs & experiments	Git-backed versions
Best Use Case	ML experimentation	Reproducible data workflows
Replacement?	âŒ No	âŒ No
Works Together?	âœ… Yes	âœ… Yes

Bottom line:

MLflow tracks experiments.
DVC tracks data & pipelines.
They complement each other â€” they donâ€™t compete.

â–¶ï¸ How to Run
1ï¸âƒ£ Install Dependencies
pip install mlflow scikit-learn matplotlib pandas

2ï¸âƒ£ Run Experiments
python src/file1.py

3ï¸âƒ£ Launch MLflow UI (Local)
mlflow ui


Open in browser:

http://127.0.0.1:5000

ğŸŒ Remote Tracking with DAGsHub

Experiments are logged to a remote MLflow server

Useful for:

Collaboration

Resume-worthy projects

Production-style workflows

Tracking URI is configured inside the script.

ğŸ“Œ Why This Project Is Valuable

Shows real ML engineering practices

Covers local + remote tracking

Demonstrates experiment reproducibility

Strong foundation for:

ML Engineer

MLOps

Research workflows

Clean and extendable setup

No toy project nonsense. This is how ML is done properly.

ğŸ”® Possible Extensions

Integrate Optuna for advanced tuning

Combine MLflow + DVC in one pipeline

Add model registry

Deploy trained model using FastAPI

Use cloud-based tracking backend

ğŸ‘¨â€ğŸ’» Author

Shaurya Tripathi
AI / ML Student
Focused on ML engineering, MLOps, and production-ready systems

ğŸ“œ License

This project is licensed under the MIT License.
